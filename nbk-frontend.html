<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>NBK Realtime Speech Test</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }

        .container {
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
            padding: 40px;
            max-width: 800px;
            width: 100%;
        }

        h1 {
            color: #333;
            margin-bottom: 10px;
            font-size: 28px;
        }

        .subtitle {
            color: #666;
            margin-bottom: 30px;
            font-size: 14px;
        }

        .config-section {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 25px;
        }

        .config-section h3 {
            color: #333;
            margin-bottom: 15px;
            font-size: 16px;
        }

        .input-group {
            margin-bottom: 15px;
        }

        label {
            display: block;
            color: #555;
            margin-bottom: 5px;
            font-size: 13px;
            font-weight: 600;
        }

        input, select {
            width: 100%;
            padding: 10px;
            border: 2px solid #e0e0e0;
            border-radius: 8px;
            font-size: 14px;
            transition: border-color 0.3s;
        }

        input:focus, select:focus {
            outline: none;
            border-color: #667eea;
        }

        .button-group {
            display: flex;
            gap: 10px;
            margin-bottom: 25px;
        }

        button {
            flex: 1;
            padding: 15px;
            border: none;
            border-radius: 10px;
            font-size: 16px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }

        button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        .btn-connect {
            background: #10b981;
            color: white;
        }

        .btn-connect:hover:not(:disabled) {
            background: #059669;
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(16, 185, 129, 0.3);
        }

        .btn-disconnect {
            background: #ef4444;
            color: white;
        }

        .btn-disconnect:hover:not(:disabled) {
            background: #dc2626;
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(239, 68, 68, 0.3);
        }

        .btn-record {
            background: #3b82f6;
            color: white;
        }

        .btn-record:hover:not(:disabled) {
            background: #2563eb;
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(59, 130, 246, 0.3);
        }

        .btn-record.recording {
            background: #ef4444;
            animation: pulse 1.5s ease-in-out infinite;
        }

        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.7; }
        }

        .status {
            padding: 15px;
            border-radius: 10px;
            margin-bottom: 20px;
            font-weight: 600;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .status-disconnected {
            background: #fee2e2;
            color: #991b1b;
        }

        .status-connecting {
            background: #fef3c7;
            color: #92400e;
        }

        .status-connected {
            background: #d1fae5;
            color: #065f46;
        }

        .status-indicator {
            width: 12px;
            height: 12px;
            border-radius: 50%;
            background: currentColor;
        }

        .transcript-section {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 20px;
        }

        .transcript-section h3 {
            color: #333;
            margin-bottom: 15px;
            font-size: 16px;
        }

        .transcript-box {
            background: white;
            border: 2px solid #e0e0e0;
            border-radius: 8px;
            padding: 15px;
            min-height: 120px;
            max-height: 200px;
            overflow-y: auto;
            font-size: 14px;
            line-height: 1.6;
            color: #333;
        }

        .transcript-box:empty::before {
            content: "Transcripts will appear here...";
            color: #999;
            font-style: italic;
        }

        .message {
            margin-bottom: 10px;
            padding: 8px 12px;
            border-radius: 6px;
        }

        .message-user {
            background: #dbeafe;
            color: #1e40af;
            text-align: right;
        }

        .message-ai {
            background: #f3f4f6;
            color: #1f2937;
        }

        .logs {
            background: #1e293b;
            color: #e2e8f0;
            padding: 15px;
            border-radius: 10px;
            max-height: 300px;
            overflow-y: auto;
            font-family: 'Courier New', monospace;
            font-size: 12px;
            line-height: 1.5;
        }

        .log-entry {
            margin-bottom: 5px;
        }

        .log-info { color: #60a5fa; }
        .log-success { color: #34d399; }
        .log-error { color: #f87171; }
        .log-warning { color: #fbbf24; }

        .footer {
            margin-top: 20px;
            text-align: center;
            color: #999;
            font-size: 12px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ðŸŽ¤ NBK Realtime Speech Test</h1>
        <p class="subtitle">Test Azure OpenAI Realtime API via APIM</p>

        <div class="config-section">
            <h3>Configuration</h3>
            <div class="input-group">
                <label for="wsUrl">WebSocket URL</label>
                <input type="text" id="wsUrl" 
                    value=""
                    placeholder="wss://your-apim.azure-api.net/inference/openai/realtime?api-version=2024-10-01-preview&deployment=gpt-realtime">
            </div>
            <div class="input-group">
                <label for="apiKey">API Key</label>
                <input type="password" id="apiKey" 
                    value=""
                    placeholder="Your APIM subscription key">
            </div>
        </div>

        <div class="status status-disconnected">
            <span class="status-indicator"></span>
            <span id="statusText">Disconnected</span>
        </div>

        <div class="button-group">
            <button id="connectBtn" class="btn-connect">Connect</button>
            <button id="disconnectBtn" class="btn-disconnect" disabled>Disconnect</button>
            <button id="recordBtn" class="btn-record" disabled>ðŸŽ¤ Hold to Speak</button>
        </div>

        <div class="transcript-section">
            <h3>Conversation</h3>
            <div class="transcript-box" id="transcriptBox"></div>
        </div>

        <details style="margin-bottom: 20px;">
            <summary style="cursor: pointer; font-weight: 600; color: #555; margin-bottom: 10px;">ðŸ“‹ Event Logs</summary>
            <div class="logs" id="logs"></div>
        </details>

        <div class="footer">
            NBK Realtime API Test Client | Powered by Azure OpenAI
        </div>
    </div>

    <script>
        let ws = null;
        let audioContext = null;
        let playbackContext = null;
        let mediaStream = null;
        let audioSource = null;
        let audioProcessor = null;
        let isRecording = false;
        let currentAudioSource = null;
        let audioQueue = [];
        let isPlayingAudio = false;

        const wsUrlInput = document.getElementById('wsUrl');
        const apiKeyInput = document.getElementById('apiKey');
        const connectBtn = document.getElementById('connectBtn');
        const disconnectBtn = document.getElementById('disconnectBtn');
        const recordBtn = document.getElementById('recordBtn');
        const statusText = document.getElementById('statusText');
        const statusDiv = document.querySelector('.status');
        const transcriptBox = document.getElementById('transcriptBox');
        const logsDiv = document.getElementById('logs');

        // Logging
        function log(message, type = 'info') {
            const entry = document.createElement('div');
            entry.className = `log-entry log-${type}`;
            entry.textContent = `[${new Date().toLocaleTimeString()}] ${message}`;
            logsDiv.appendChild(entry);
            logsDiv.scrollTop = logsDiv.scrollHeight;
        }

        function updateStatus(text, state) {
            statusText.textContent = text;
            statusDiv.className = `status status-${state}`;
        }

        function addTranscript(text, isUser = false) {
            const message = document.createElement('div');
            message.className = `message ${isUser ? 'message-user' : 'message-ai'}`;
            message.textContent = text;
            transcriptBox.appendChild(message);
            transcriptBox.scrollTop = transcriptBox.scrollHeight;
        }

        // Connect to WebSocket
        connectBtn.addEventListener('click', async () => {
            const url = wsUrlInput.value.trim();
            const apiKey = apiKeyInput.value.trim();

            if (!url || !apiKey) {
                log('Please provide WebSocket URL and API Key', 'error');
                return;
            }

            try {
                updateStatus('Connecting...', 'connecting');
                connectBtn.disabled = true;
                log('Connecting to WebSocket...', 'info');

                // For browser WebSocket, add api-key as query parameter
                const urlWithKey = url + `&api-key=${encodeURIComponent(apiKey)}`;
                ws = new WebSocket(urlWithKey);

                ws.onopen = () => {
                    log('WebSocket connected!', 'success');
                    updateStatus('Connected', 'connected');
                    connectBtn.disabled = true;
                    disconnectBtn.disabled = false;
                    recordBtn.disabled = false;

                    // DO NOT send session config - backend handles all configuration
                    // including system prompt, voice (Echo), VAD settings, and NBK knowledge
                    log('Session will be configured by backend', 'info');
                };

                ws.onmessage = (event) => {
                    const data = JSON.parse(event.data);
                    handleWebSocketMessage(data);
                };

                ws.onerror = (error) => {
                    log(`WebSocket error: ${error}`, 'error');
                };

                ws.onclose = () => {
                    log('WebSocket disconnected', 'warning');
                    updateStatus('Disconnected', 'disconnected');
                    connectBtn.disabled = false;
                    disconnectBtn.disabled = true;
                    recordBtn.disabled = true;
                    ws = null;
                };

            } catch (error) {
                log(`Connection failed: ${error.message}`, 'error');
                updateStatus('Connection Failed', 'disconnected');
                connectBtn.disabled = false;
            }
        });

        // Disconnect
        disconnectBtn.addEventListener('click', () => {
            if (ws) {
                ws.close();
                log('Disconnecting...', 'info');
            }
        });

        // Handle WebSocket messages
        function handleWebSocketMessage(data) {
            const type = data.type;

            switch(type) {
                case 'session.created':
                    log('Session created', 'success');
                    break;
                
                case 'session.updated':
                    log('Session updated', 'info');
                    break;

                case 'response.audio_transcript.delta':
                    // Accumulate transcript
                    const transcript = data.delta;
                    log(`Transcript delta: ${transcript}`, 'info');
                    break;

                case 'response.audio_transcript.done':
                    const fullTranscript = data.transcript;
                    log(`Full transcript: ${fullTranscript}`, 'success');
                    addTranscript(fullTranscript, false);
                    break;

                case 'response.audio.delta':
                    // Receive audio chunk
                    const audioData = data.delta;
                    playAudioChunk(audioData);
                    break;

                case 'response.audio.done':
                    log('Audio response complete', 'success');
                    break;

                case 'input_audio_buffer.speech_started':
                    log('Speech detected', 'info');
                    break;

                case 'input_audio_buffer.speech_stopped':
                    log('Speech ended', 'info');
                    break;

                case 'error':
                    log(`Error: ${data.error.message}`, 'error');
                    break;

                default:
                    log(`Event: ${type}`, 'info');
            }
        }

        // Audio playback with queue to prevent overlapping
        function playAudioChunk(base64Audio) {
            audioQueue.push(base64Audio);
            if (!isPlayingAudio) {
                processAudioQueue();
            }
        }

        async function processAudioQueue() {
            if (audioQueue.length === 0) {
                isPlayingAudio = false;
                return;
            }

            isPlayingAudio = true;
            const base64Audio = audioQueue.shift();

            try {
                if (!playbackContext) {
                    playbackContext = new (window.AudioContext || window.webkitAudioContext)({
                        sampleRate: 24000
                    });
                }

                // Stop any currently playing audio
                if (currentAudioSource) {
                    try {
                        currentAudioSource.stop();
                    } catch (e) {
                        // Already stopped
                    }
                    currentAudioSource = null;
                }

                // Decode base64 to binary
                const binaryString = atob(base64Audio);
                const bytes = new Uint8Array(binaryString.length);
                for (let i = 0; i < binaryString.length; i++) {
                    bytes[i] = binaryString.charCodeAt(i);
                }

                // Convert PCM16 to Float32
                const int16Array = new Int16Array(bytes.buffer);
                const float32Array = new Float32Array(int16Array.length);
                for (let i = 0; i < int16Array.length; i++) {
                    float32Array[i] = int16Array[i] / 32768.0;
                }

                // Create audio buffer
                const audioBuffer = playbackContext.createBuffer(1, float32Array.length, 24000);
                audioBuffer.getChannelData(0).set(float32Array);

                // Play audio
                const source = playbackContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(playbackContext.destination);
                currentAudioSource = source;
                
                source.onended = () => {
                    currentAudioSource = null;
                    processAudioQueue();
                };
                
                source.start();

            } catch (error) {
                log(`Audio playback error: ${error.message}`, 'error');
                currentAudioSource = null;
                processAudioQueue();
            }
        }

        // Record audio
        recordBtn.addEventListener('mousedown', startRecording);
        recordBtn.addEventListener('mouseup', stopRecording);
        recordBtn.addEventListener('touchstart', startRecording);
        recordBtn.addEventListener('touchend', stopRecording);

        async function startRecording() {
            if (!ws || ws.readyState !== WebSocket.OPEN) {
                log('Not connected to WebSocket', 'error');
                return;
            }

            try {
                log('Starting recording...', 'info');
                recordBtn.textContent = 'ðŸ”´ Recording...';
                recordBtn.classList.add('recording');

                // Request microphone access
                mediaStream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    } 
                });

                // Create audio context for recording
                audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
                audioSource = audioContext.createMediaStreamSource(mediaStream);
                
                // Use ScriptProcessor for compatibility
                audioProcessor = audioContext.createScriptProcessor(2048, 1, 1);

                audioProcessor.onaudioprocess = (e) => {
                    if (!isRecording || !ws || ws.readyState !== WebSocket.OPEN) return;

                    const inputData = e.inputBuffer.getChannelData(0);
                    const pcm16 = new Int16Array(inputData.length);
                    
                    // Convert float32 to int16
                    for (let i = 0; i < inputData.length; i++) {
                        const s = Math.max(-1, Math.min(1, inputData[i]));
                        pcm16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
                    }

                    // Convert to base64
                    const base64Audio = btoa(String.fromCharCode.apply(null, new Uint8Array(pcm16.buffer)));

                    // Send to WebSocket
                    ws.send(JSON.stringify({
                        type: 'input_audio_buffer.append',
                        audio: base64Audio
                    }));
                };

                audioSource.connect(audioProcessor);
                audioProcessor.connect(audioContext.destination);

                isRecording = true;
                log('Recording started - speak now!', 'success');

            } catch (error) {
                log(`Recording error: ${error.message}`, 'error');
                recordBtn.textContent = 'ðŸŽ¤ Hold to Speak';
                recordBtn.classList.remove('recording');
                cleanupRecording();
            }
        }

        function stopRecording() {
            if (!isRecording) return;

            isRecording = false;
            recordBtn.textContent = 'ðŸŽ¤ Hold to Speak';
            recordBtn.classList.remove('recording');

            log('Recording stopped', 'warning');

            // Commit audio buffer and request response
            if (ws && ws.readyState === WebSocket.OPEN) {
                ws.send(JSON.stringify({
                    type: 'input_audio_buffer.commit'
                }));
                ws.send(JSON.stringify({
                    type: 'response.create'
                }));
                log('Audio committed, requesting response...', 'info');
            }

            cleanupRecording();
        }

        function cleanupRecording() {
            if (audioProcessor) {
                audioProcessor.disconnect();
                audioProcessor = null;
            }
            if (audioSource) {
                audioSource.disconnect();
                audioSource = null;
            }
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
                mediaStream = null;
            }
            if (audioContext && audioContext.state !== 'closed') {
                audioContext.close();
                audioContext = null;
            }
        }

        // Load values from .env on page load
        log('Ready to connect', 'info');
    </script>
</body>
</html>

